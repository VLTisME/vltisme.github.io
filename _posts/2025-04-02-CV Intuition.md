---
title: Intuition in Computer Vision
date: 2025-04-02 15:00:00 +0700
categories: [AI, DL]
tags: [computer vision, intuition]     # TAG names should always be lowercase
authors: [tuan]

description: "This is exactly how I visualize and understand things so easily (or not)."
toc: false
comments: true

---




This is only for R-CNN related stuff: (learn the abstract first - understand the architecture, we use X, Y , Z in here,â€¦ then what does X do, Y do, Z do? â†’ then deepdive into theory - how is it structured? how does it do so well? why does it work? â†’ then into Code, wats the workflow? where should i study fist? which part of the code should be read first?

Note:

- Why R-CNN is slow? â†’ Due to 3 independent modules: it must first propose regions, then each region is fed into CNN to extract module
- How Fast R-CNN optimizes it? It use only one single model instead of a pipeline like above.

Understand Fast-RCNN:

- Ban Ä‘áº§u sáº½ feed vÃ o má»™t táº¥m áº£nh, táº¥m áº£nh Ä‘Ã³, thay vÃ¬ Ã¡p dá»¥ng region proposal nhÆ° R-CNN Ä‘á»ƒ ra má»™t má»› regions thÃ¬ nÃ³ láº¡i Ä‘Æ°á»£c truyá»n qua má»™t Deep CNN Ä‘á»ƒ trÃ­ch xuáº¥t ra feature map. Váº­y lÃ m sao Ä‘á»ƒ biáº¿t vá»‹ trÃ­ cá»§a má»™t region trÃªn feature map Ä‘Ã³? chÃºng ta sáº½ dÃ¹ng phÃ©p chiáº¿u Rol Ä‘á»ƒ â€œtÆ°Æ¡ng Ä‘á»‘iâ€ Ä‘Æ°á»£c vá»‹ trÃ­ cá»§a region Ä‘Ã³ trÃªn áº£nh gá»‘c. sau Ä‘Ã³ truyá»n cáº£ káº¿t quáº£ cá»§a rol projection vÃ  feature map (LÆ°u Ã½ lÃ  truyá»n duy nháº¥t 1 rol vÃ o thÃ´i, ko truyá»n cáº£ chÃ¹m) vÃ o cÃ¡c rol pooling layers , rá»“i vÃ o FCs Ä‘á»ƒ thu Ä‘Æ°á»£c cÃ¡c rol feature vectors. Sau Ä‘Ã³ cÃ¡c rol feature vectors sáº½ Ä‘i qua 2 nhÃ¡nh. 1 NhÃ¡nh giÃºp xÃ¡c Ä‘á»‹nh phÃ¢n phá»‘i xÃ¡c suáº¥t theo cÃ¡c class cá»§a 1 vÃ¹ng quan tÃ¢m RoI thÃ´ng qua hÃ m softmax vÃ  nhÃ¡nh cÃ²n xÃ¡c Ä‘á»‹nh tá»a Ä‘á»™ cá»§a bounding box thÃ´ng qua há»“i qui cÃ¡c offsets.

Faster-RCNN:

- NÃ³ thá»±c cháº¥t lÃ  sá»± káº¿t há»£p cá»§a hai modules riÃªng láº»: Fast-RCNN vÃ  RPN (region proposal network) - RPN lÃ  má»™t CNN Ä‘á»ƒ Ä‘á» xuáº¥t cÃ¡c vÃ¹ng vÃ  loáº¡i Ä‘á»‘i tÆ°á»£ng cáº§n xem xÃ©t trong vÃ¹ng.

tá»©c lÃ  cÅ©ng nhÆ° Fast-RCNN á»Ÿ trÃªn, Faster RCNN nÃ³ sáº½ tá»‘i Æ°u á»Ÿ cÃ¡i chá»— Rol projection (nÃ³ sáº½ ko táº¡o rol projection trÃªn featuremap), nÃ³ sáº½ dÃ¹ng RPN Ä‘á»ƒ trÃ­ch xuáº¥t Ã­t vÃ¹ng hÆ¡n nhiá»u tá»« nhá»¯ng cÃ¡i feature maps sau khi input flow qua DCNN, rá»“i sá»‘ vÃ¹ng Ä‘á» xuáº¥t Ä‘Æ°á»£c sáº½ cÃ¹ng Ä‘Æ°á»£c feed vÃ o rol pooling layers vá»›i feature maps tá»« DCNN. vÃ  cÅ©ng khÃ¡c á»Ÿ chá»— lÃ  á»Ÿ Fast RCNN, nÃ³ ko táº¡o Rol Projection mÃ  dÃ¹ng RPN Ä‘á»ƒ táº¡o ra regions tá»« output cá»§a DCNN luÃ´n. DCNN thÆ°á»ng lÃ  VGG-16, ResNet,â€¦

á»“ vÃ  RPN nÃ³ propose regions vÃ  nhá»¯ng regions Ä‘Ã³ lÃ  bounding box luÃ´n rá»“i nÃªn ta chá»‰ cáº§n dÃ¹ng feature map, Ä‘Æ°a feature map vÃ o má»™t classifier lÃ  xong, ko cáº§n regressor Ä‘á»ƒ tÃ¬m bounding box.

Mask-RCNN:

cÃ¡i viá»‡c dá»± Ä‘oÃ¡n nhÃ£n cá»§a region Ä‘Ã³ vÃ  masking nÃ³ sáº½ Ä‘Æ°á»£c cháº¡y song song!

khi mÃ  qua backbone (resnet + FPN) Ã¡, thÃ¬ nÃ³ cho ra cÃ¡i feature map ok, rá»“i RPN nÃ³ sáº½ trÃ­ch xuáº¥t regions ra tá»« feature map Ä‘Ã³, mÃ  cÃ¡c regions Ä‘Ã³ chÆ°a biáº¿t vá»‹ trÃ­ trong áº£nh gá»‘c lÃ  ntn nÃªn sáº½ Ä‘Æ°a cÃ¡i feature map vÃ  regions Ä‘Ã³ vÃ o RoIAlign Ä‘á»ƒ Æ°á»›c tÃ­nh vá»‹ trÃ­ cá»§a regions Ä‘Ã³ trong áº£nh gá»‘c, vÃ  RolAlign cÃ²n lÃ m cáº£ viá»‡c extract features cho má»—i region Ä‘Æ°á»£c proposed â†’ hÃ¬nh nhÆ° ko pháº£i, mÃ  lÃ  vÃ¬ regions proposed thÃ¬ cÃ³ size khÃ¡c nhau nÃªn lÃ m sao mÃ  feed vÃ o NN sau Ä‘Ã³ má»™t cÃ¡ch hiá»‡u quáº£ Ä‘Æ°á»£c? nÃªn RoIAlign má»›i Ä‘Æ°a chÃºng nÃ³ vá» fixed size rá»“i má»›i feed vÃ o NN (Trong paper gá»i váº¥n Ä‘á» Ä‘Ã³ lÃ  â€œmisalignmentâ€ Ä‘Ã³) â†’ ÄÃºng, cÃ²n viá»‡c loáº¡i bá» regions ko quan trá»ng thÃ¬ Ä‘Ã£ lÃ m á»Ÿ RPN

â†’ RPN nÃ³ Ä‘Æ°a ra bounding box (aka RoI) vá»›i láº¡i objectness score, xong rá»“i láº¥y káº¿t quáº£ Ä‘Ã³, káº¿t há»£p vá»›i feature maps (nhá»› lÃ  feature maps chá»© ko pháº£i original image), káº¿t há»£p á»Ÿ Ä‘Ã¢y Ã½ mÃ¬nh lÃ  nÃ³ chiáº¿u cÃ¡i vÃ¹ng Ä‘á» xuáº¥t lÃªn feature map Ä‘á»ƒ láº¥y thÃ´ng tin cÃ¡i vÃ¹ng Ä‘Ã³ á»Ÿ feature map rá»“i feed vÃ o tháº±ng tháº±ng RoIAlign, rá»“i vá»›i má»—i vÃ¹ng Ä‘á» xuáº¥t trÃ­ch ra tá»« feature map RoIAlign sáº½ dÃ¹ng Bilinear interpolation Ä‘á»ƒ tÃ¡i hiá»‡n láº¡i gáº§n Ä‘Ãºngâ€¦ rá»“i nÃ³ normalizes/ aligns all káº¿t quáº£ sau khi bilinear interpolation vá» cÃ¹ng má»™t size rá»“i feed vÃ o FCs á»Ÿ sau.

â†’ RolAlign: first it takes the RoI (the bounding box) and extract info from the feature map of that RoI, then it divide the RoI into smaller bins (7x7 for classification and 14x14 for masking?), it divides into floating points coordinate (e.g: RoI size is 40x40 then each bin will cover ~5.7 x 5.7 pixels on the feature map) â†’ then it uses Bilinear Interpolation with values in the feature map from backbone.

question: why would resizing into 7x7 work well in practice (e.g if 40x40 contains a giraffe, then doesnt 7x7 contain only a part of that giraffe and make the model predict poorly?): 

- The input to RoIAlign is not the raw image but theÂ **feature map**Â produced by the backbone (e.g., ResNet, FPN). These feature maps already encode high-level semantic information about the object (e.g., "giraffe") in aÂ **spatially compressed form**.
- For example, if the backbone downsamples the image by a factor of 16, a 40Ã—40 region on the feature map corresponds to a much larger region (640Ã—640) in the original image. The feature map has already condensed the visual information into a smaller, more abstract representation.

**â†’ this means your understanding about conv is not corret, a kernel size does relate to the region, the size it looks, but you forgot that even if a kernel size of just 5x5 can capture the whole 40x40 giraffe thanks to sliding the kernel over the picture and outputs a lot of channels, each channel preserves informations about the giraffe (ex: its ears, its body, its heads,â€¦) and the network can â€œcombineâ€ these spatial information into bigger one to reshape the giraffe! so interesting! And also, small kernel size can capture smaller object like a squirrel on the giraffeâ€™s back!!! kernel size not only able to capture large or small object but can also act as a â€œscissorâ€ to cut the image into smaller parts, each part retains information, and then reconstruct it later!â€**

question: larger bin will capture large region but why do we also use large bin to mask very small object like a distant bird?:

- You're absolutely right to ask this! If a distant bird (a very small object) corresponds to a small region on the feature map, then dividing it into relativelyÂ **large bins**Â (as part of a fixedÂ `7Ã—7`Â orÂ `14Ã—14`Â grid) might seem counterintuitive.
- oh simply just big region or small region will be divided equallyâ€¦ by 14? hm?

hm hÃ£y sáºµn sÃ ng Ä‘á»ƒ tÆ°á»Ÿng tÆ°á»£ng Ä‘iá»u thÃº vá»‹ nÃ y mÃ¬nh nghÄ©:

- XÃ©t má»™t CNN, thÆ°á»ng thÃ¬ cÃ¡c kernel size ban Ä‘áº§u sáº½ lá»›n xong nhá» dáº§n. Äá»ƒ lÃ m gÃ¬? kernel size lá»›n thÃ¬ nÃ³ capture Ä‘Æ°á»£c má»™t vÃ¹ng áº£nh rá»™ng hÆ¡nâ€¦ â†’ sau Ä‘Ã³ lan truyá»n vÃ  lan truyá»n thÃ´ng tin qua cÃ¡c layers sauâ€¦ vÃ  lan truyá»n nhiá»u quÃ¡ rá»“i thÃ¬ hÆ¡i sá»£ máº¥t thÃ´ng tin cá»§a vÃ¹ng áº£nh Ä‘Ã³ do exploding hoáº·c vanishing gradient descent nÃªn sáº½ cÃ³ residual connections â†’ xong rá»“i Ä‘á»ƒ xÃ©t má»™t vÃ¹ng áº£nh nhá» hÆ¡n liá»‡u cÃ³ gÃ¬ Ä‘áº·c biá»‡t Ä‘Ã¡ng chÃº Ã½ khÃ´ng (vÃ­ dá»¥ vÃ¹ng lá»›n cÃ³ con hÆ°u cao cá»•, vÃ¹ng nhá» cÃ³ con khá»‰ ngá»“i trÃªn lÆ°ng hÆ°u cao cá»•) thÃ¬ ta tiáº¿p tá»¥c introduce smaller kernel size Ä‘á»‘i cho cÃ¡c lá»›p sau Ä‘á»ƒ cÃ¡i kernel size Ä‘Ã³ tiáº¿p tá»¥c capture má»™t vÃ¹ng nhá» cá»§a cÃ¡i vÃ¹ng áº£nh lá»›n ban Ä‘áº§u! â†’ deeper network + techniques = capture more specific context. - Tháº­t ra cÅ©ng khÃ´ng háº³n =)) ko cáº§n pháº£i kernel size cÃ ng ngÃ y cÃ ng nhá», vÃ­ dá»¥ nhÆ° nÃ³ = 2 miáº¿t thÃ¬ váº«n Ä‘Æ°á»£c mÃ  =)).

â†’ há»i chatgpt vá» intuition cá»§a nhá»¯ng kÄ© thuáº­t trong CV Ä‘i, thÃº vá»‹ láº¯m. VD nhÆ° batchnorm thÃ¬ há»¯u Ã­ch khi mÃ  cÃ³ má»™t feature quan trá»ng nhÆ°ng dao Ä‘á»™ng trong khoáº£ng [0-1] cÃ²n cÃ³ tháº±ng dao Ä‘á»™ng tá»« [0-10000].

ThÃ¬ nhá»¯ng tháº±ng trÃªn lÃ  OK vá» máº·t Object Detection rá»“i, nÃ¢ng cao hÆ¡n ná»¯a vá» object detection sáº½ lÃ  vá» YOLO familyâ€¦ nhÆ°ng mÃ  mÃ¬nh sáº¯p tá»›i thi vá» â€œinstance segmentationâ€ nÃªnâ€¦ tiáº¿p theo sáº½ khÃ´ng há»c YOLO mÃ  lÃ  Mask R-CNN ğŸ˜² vá»«a cÃ³ kháº£ nÄƒng object detection vá»«a cÃ³ kháº£ nÄƒng masking.

**thÃº tháº­t**, máº·c dÃ¹ Ä‘á»c paper, má»™t thá»© cá»±c kÃ¬ chuyÃªn sÃ¢u vÃ  chi tiáº¿t, nhÆ°ng mÃ¬nh váº«n ráº¥t dá»… hiá»ƒu vÃ  náº¯m cháº¯c kiáº¿n thá»©c vÃ¬- mÃ¬nh Ä‘Ã£ há»c nÃ³ má»™t cÃ¡ch abstract rá»“i :))) mÃ¬nh Ä‘Ã£ Ä‘á»c qua cÃ¡c blog overview vá» nÃ³ vÃ  biáº¿t nÃ³ cÃ³ gÃ¬, nÃ³ lÃ m Ä‘Æ°á»£c gÃ¬, nÃ³ tá»‘i Æ°u cÃ¡i gÃ¬,â€¦ cÃ²n Ä‘á»c paper chá»‰ lÃ  Ä‘á»ƒ biáº¿t nÃ³ lÃ m nhá»¯ng Ä‘iá»u Ä‘Ã³ nhÆ° tháº¿ nÃ o thÃ´i, vÃ  há»‡ thá»‘ng láº¡i kiáº¿n thá»©c.

tÃ³m táº¯t sÆ¡ láº¡i workflow há»c cá»§a mÃ¬nh: Thi vá» Instance segmentation â†’ há»i chatGPT vá» nhá»¯ng model tá»‘t nháº¥t â†’ lá»±a ra 1 model Ä‘á»ƒ há»c â†’ há»i chatgpt vá» prequesites cáº§n cÃ³ Ä‘á»ƒ há»c model Ä‘Ã³ â†’ â€¦ ok bh lÃ  Ä‘á»‘i vá»›i tá»«ng prequisite, hoáº·c lÃ  model â†’ há»i chatgpt Ä‘Æ°a ra roadmap Ä‘á»ƒ mÃ¬nh há»c vá» thá»© Ä‘Ã³ â†’ xem thá»­ model Ä‘Ã³ cÃ³ nhá»¯ng thÃ nh pháº§n gÃ¬ vÃ  cÃ´ng dá»¥ng tá»«ng thÃ nh pháº§n, nhá» chatgpt nÃ³i vá» workflow cá»§a model Ä‘Ã³, tá»± mÃ¬nh giáº£i thÃ­ch vÃ  tÆ°á»Ÿng tÆ°á»£ng láº¡i workflow â†’ deepdive into each component: Ä‘Ã o sÃ¢u vÃ o tá»«ng thÃ nh pháº§n, hiá»ƒu Ä‘Æ°á»£c cÃ´ng thá»©c cá»§a nÃ³, intuition Ä‘áº±ng sau nÃ³, lÃ m sao nÃ³ cÃ³ cÃ´ng dá»¥ng nhÆ° váº­yâ€¦ tá»± giáº£i thÃ­ch láº¡i (Ä‘oáº¡n nÃ y nÃªn ghi láº¡i táº¥t táº§n táº­t components cá»§a model lá»›n theo nhÆ° workflow chatgpt nÃ³i, rá»“i dá»±a vÃ o nhá»¯ng gÃ¬ Ä‘Ã£ ghi Ä‘á»ƒ nhá» chatgpt giáº£i thÃ­ch tá»«ng pháº§n) â†’ sau khi Ä‘Ã£ hiá»ƒu rÃµ tá»«ng thÃ nh pháº§n cá»§a má»™t model lá»›n rá»“i thÃ¬ quay láº¡i Ä‘á»c chuyÃªn sÃ¢u paper cá»§a model lá»›n, lÃºc nÃ y Ä‘á»c Ä‘áº¿n Ä‘Ã¢u cÅ©ng hiá»ƒu Ä‘áº¿n Ä‘Ã³ vÃ¬ cÃ¡c khÃ¡i niá»‡m trong paper lá»›n mÃ¬nh Ä‘Ã£ há»c háº¿t rá»“i! â†’ xong xuÃ´i háº¿t rá»“i thÃ¬ tá»± tá»•ng há»£p láº¡i táº¥t táº§n táº­t tá»« Ä‘áº§u Ä‘áº¿n cuá»‘i láº¡i má»™t láº§n ná»¯a: kiáº¿n trÃºc cá»§a model lÃ  gÃ¬? thÃ nh pháº§n nÃ y cÃ³ chá»©c nÄƒng gÃ¬? táº¡i sao nÃ³ lÃ m Ä‘Æ°á»£c nhÆ° váº­y? workflow cá»§a model Ä‘Ã³ lÃ  nhÆ° tháº¿ nÃ o. 

TÆ°Æ¡ng tá»± cho coding phase: hiá»ƒu workflow cá»§a code trÆ°á»›c Ä‘Ã£, rá»“i xem thá»­ cáº§n pháº£i há»c nhá»¯ng gÃ¬ (prequesites) Ä‘á»ƒ hiá»ƒu code? rá»“i má»›i Ä‘á»c kÄ© tá»«ng pháº§n cá»§a code, rá»“i code láº¡i!.

â€œTell me the workflow of model X, and each of its componentâ€™s usage, the intution behind it (overview and abstract part). Then provide me a roadmap to learn these components first, in order from what need to study first to harder parts. Then learn each component, for each component, ask ChatGPT besides mathematical knowledge, what are the prequesites to understand that component? Then continue divide and conquer,â€¦ once the smaller part is done, back to the larger part, then largerâ€¦ largest! (breakdown the big picture into smaller ones, then continue breaking down the smaller into even smaller ones, then study from the smallest, to understand the second smallest,â€¦ to the big picture!).

**Yayâ€¦ khÃ¡m phÃ¡ ra cÃ¡ch há»c Ä‘á»‰nh cao há»c siÃªu nhanh! Chá»‰ trong 30p mÃ  mÃ¬nh hiá»ƒu háº¿t 3 architecturÃ©s OMG! ra Ä‘Ã¢y lÃ  sá»©c máº¡nh cá»§a CÃCH Há»ŒC â†’ Ä‘Ã³ lÃ : pháº£i biáº¿t há»c gÃ¬ trÆ°á»›c (ask ChatGPT) â†’ há»c cÃ¡i rá»™ng, bao quÃ¡t, trá»«u tÆ°á»£ng Ä‘á»ƒ náº¯m Ä‘Æ°á»£c workflow cá»§a nÃ³, cÃ¡ch nÃ³ hoáº¡t Ä‘á»™ng (Ä‘á»c overview vá» nÃ³, biáº¿t nÃ³ cÃ³ gÃ¬ xong biáº¿t nÃ³ dÃ¹ng Ä‘á»ƒ lÃ m gÃ¬, what does it use and what does it do?) â†’ deepdive into tá»«ng pháº§n (lÃ m sao nÃ³ lÃ m Ä‘Æ°á»£c nhÆ° váº­y? cÃ´ng thá»©c cá»§a nÃ³ lÃ  gÃ¬? How does it do that?) (Ã¡p dá»¥ng cho cáº£ viá»‡c Ä‘á»c paper or há»c má»™t kiáº¿n thá»©c má»›i vÃ  coding phase).**

Continue Mask-RCNN paper reading (remember: from abstract, overview to deepdive into each part then back to the big picture) â†’ Coding phase (remember: understand the workflow first then understand each file later). Ã”n kÄ© láº¡i intuition tá»«ng li tá»«ng tÃ­ Mask RCNN (nhÆ° lÃ  Ã½ nghÄ©a cá»§a RPN, RoIAlign, Backbone architecture,â€¦) vÃ  cÃ¡c thao tÃ¡c khÃ¡c trong boxchat intuition & life vá»›i sider. Viáº¿t blog vá» Mask-RCNN tháº­t kÄ© cÃ ng vÃ  dá»… hiá»ƒu theo kiá»ƒu Intuition & há»c kiá»ƒu má»›i cá»§a mÃ¬nh Ä‘á»ƒ cho nhÃ³m AIC cá»§a mÃ¬nh Ä‘á»c. CÃ³ thá»ƒ Ä‘á»c nhanh DETR

â€œYou must be the one with the model to understand the power of it. Once fully understand it, it is like understanding yourselfâ€ - â€œTo create a new model, think like yourself is the current models, all the techniques you know, and specify the problem, what do you have to solve it, what do you lack of, what is not good enough, what if we get rid of this, add something new, change it to something we have never seenâ€¦â€?. 

